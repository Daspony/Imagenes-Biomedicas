{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 05: Denoising en CT - LDCT a NDCT\n",
    "\n",
    "Este notebook implementa tecnicas de reduccion de ruido (denoising) en imagenes CT pulmonares.\n",
    "\n",
    "## Contenido:\n",
    "1. **Dataset Mayo Clinic (TCIA)**: Pares reales NDCT/LDCT (descarga automatica)\n",
    "2. **Alternativa**: Simulacion de ruido LDCT desde LUNA16\n",
    "3. **Tecnicas de Denoising**: Filtros clasicos vs Deep Learning (DnCNN)\n",
    "4. **Metricas de Calidad**: PSNR, SSIM, MSE\n",
    "\n",
    "---\n",
    "\n",
    "## Datasets\n",
    "\n",
    "| Dataset | Tipo | Tamano | Descarga |\n",
    "|---------|------|--------|----------|\n",
    "| **Mayo Clinic LDCT** | Pares reales NDCT/LDCT | ~200 GB (Chest) | Automatica via tcia_utils |\n",
    "| **LUNA16** | Solo NDCT (simular ruido) | ~13 GB | Automatica |\n",
    "\n",
    "**Flujo del notebook:**\n",
    "1. Intentar descargar/usar datos reales Mayo Clinic\n",
    "2. Si no disponible, usar LUNA16 con ruido simulado\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuración del Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configuracion del entorno\nimport sys\nimport os\nfrom pathlib import Path\nimport pandas as pd\n\nIN_COLAB = 'google.colab' in sys.modules\n\n# ============================================================\n# CONFIGURACION\n# ============================================================\nUSE_MAYO_DATA = True  # Intentar usar datos reales Mayo Clinic\nMAX_MAYO_PATIENTS = 5  # Pacientes a descargar (None = todos los de Chest)\n\nif IN_COLAB:\n    print(\"Ejecutando en Google Colab\")\n    print(\"=\"*50)\n    \n    # Instalar dependencias\n    import subprocess\n    paquetes = ['SimpleITK', 'scikit-image', 'tcia_utils', 'pydicom']\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + paquetes)\n    \n    # Clonar repositorio\n    repo_url = \"https://github.com/Daspony/Imagenes-Biomedicas.git\"\n    if not os.path.exists(\"/content/Imagenes-Biomedicas\"):\n        subprocess.run([\"git\", \"clone\", repo_url], cwd=\"/content\", check=True)\n    sys.path.insert(0, \"/content/Imagenes-Biomedicas\")\n    \n    project_root = \"/content/Imagenes-Biomedicas\"\n    \n    # Montar Drive para guardar datos y modelos\n    from google.colab import drive\n    drive.mount('/content/drive')\n    \n    # Rutas en Drive (persistentes)\n    drive_data = \"/content/drive/MyDrive/CT_Denoising\"\n    os.makedirs(drive_data, exist_ok=True)\n    MAYO_PATH = os.path.join(drive_data, \"Mayo_LDCT\")\n    weights_dir = os.path.join(drive_data, \"weights\")\n    \n    # LUNA16 para fallback\n    LUNA16_PATH = os.path.join(project_root, \"LUNA16\")\n    \n    print(f\"[OK] Datos se guardaran en: {drive_data}\")\nelse:\n    print(\"Ejecutando localmente\")\n    print(\"=\"*50)\n    \n    # Instalar tcia_utils si no esta\n    try:\n        import tcia_utils\n    except ImportError:\n        import subprocess\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"tcia_utils\", \"pydicom\"])\n    \n    parent_dir = os.path.abspath('..')\n    if parent_dir not in sys.path:\n        sys.path.insert(0, parent_dir)\n    \n    project_root = parent_dir\n    MAYO_PATH = os.path.join(project_root, \"Mayo_LDCT\")\n    weights_dir = os.path.join(project_root, \"weights\")\n    LUNA16_PATH = os.path.join(project_root, \"LUNA16\")\n\nos.makedirs(weights_dir, exist_ok=True)\nprint(f\"\\nProyecto: {project_root}\")\nprint(f\"Mayo LDCT: {MAYO_PATH}\")\nprint(f\"LUNA16: {LUNA16_PATH}\")\nprint(f\"Weights: {weights_dir}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# DESCARGA AUTOMATICA - MAYO CLINIC LDCT (TCIA)\n# ============================================================\nfrom tcia_utils import nbia\nfrom tqdm import tqdm\n\ndef download_mayo_ldct(download_path, body_part=\"CHEST\", max_patients=5):\n    \"\"\"\n    Descarga pares NDCT/LDCT del dataset Mayo Clinic (TCIA)\n    Con barra de progreso para monitorear la descarga.\n    \"\"\"\n    os.makedirs(download_path, exist_ok=True)\n    \n    # Verificar si ya hay datos\n    existing_files = list(Path(download_path).rglob(\"*.dcm\"))\n    if len(existing_files) > 100:\n        print(f\"[OK] Dataset Mayo ya existe: {len(existing_files)} archivos DICOM\")\n        return True\n    \n    print(f\"[INFO] Buscando series de {body_part} en TCIA...\")\n    \n    try:\n        # Obtener series del dataset Mayo LDCT\n        series = nbia.getSeries(collection=\"LDCT-and-Projection-data\")\n        \n        if series is None or len(series) == 0:\n            print(\"[WARNING] No se encontraron series en TCIA\")\n            return False\n        \n        # Convertir a DataFrame para filtrar\n        df = pd.DataFrame(series)\n        print(f\"[INFO] Series totales: {len(df)}\")\n        \n        # Filtrar por body part\n        if 'BodyPartExamined' in df.columns:\n            df_filtered = df[df['BodyPartExamined'].str.upper() == body_part.upper()]\n            print(f\"[INFO] Series de {body_part}: {len(df_filtered)}\")\n        else:\n            df_filtered = df\n        \n        if len(df_filtered) == 0:\n            print(f\"[WARNING] No hay series de {body_part}\")\n            return False\n        \n        # Limitar numero de pacientes\n        if max_patients and 'PatientID' in df_filtered.columns:\n            unique_patients = df_filtered['PatientID'].unique()[:max_patients]\n            df_filtered = df_filtered[df_filtered['PatientID'].isin(unique_patients)]\n            print(f\"[INFO] Limitando a {len(unique_patients)} pacientes ({len(df_filtered)} series)\")\n        \n        # Descargar serie por serie con progreso\n        print(f\"\\n[INFO] Descargando {len(df_filtered)} series...\")\n        series_list = df_filtered.to_dict('records')\n        \n        successful = 0\n        failed = 0\n        \n        for i, serie in enumerate(tqdm(series_list, desc=\"Descargando series\")):\n            try:\n                # Descargar una serie a la vez\n                nbia.downloadSeries(\n                    [serie],  # Lista con una sola serie\n                    path=download_path,\n                    csv_filename=None  # No crear CSV por cada serie\n                )\n                successful += 1\n            except Exception as e:\n                failed += 1\n                print(f\"\\n[WARNING] Error en serie {i+1}: {e}\")\n        \n        print(f\"\\n[OK] Descarga completada: {successful} exitosas, {failed} fallidas\")\n        print(f\"[OK] Datos en: {download_path}\")\n        return successful > 0\n        \n    except Exception as e:\n        print(f\"[ERROR] Error descargando Mayo: {e}\")\n        return False\n\n\n# ============================================================\n# INTENTAR OBTENER DATOS MAYO\n# ============================================================\nprint(\"=\"*60)\nprint(\"DATASET MAYO CLINIC LDCT\")\nprint(\"=\"*60)\n\nMAYO_AVAILABLE = False\n\nif USE_MAYO_DATA:\n    # Verificar si ya existe\n    existing_dcm = list(Path(MAYO_PATH).rglob(\"*.dcm\")) if os.path.exists(MAYO_PATH) else []\n    \n    if len(existing_dcm) > 100:\n        MAYO_AVAILABLE = True\n        print(f\"[OK] Mayo LDCT encontrado: {len(existing_dcm)} archivos DICOM\")\n    else:\n        print(\"[INFO] Intentando descargar Mayo LDCT...\")\n        MAYO_AVAILABLE = download_mayo_ldct(\n            download_path=MAYO_PATH,\n            body_part=\"CHEST\",\n            max_patients=MAX_MAYO_PATIENTS\n        )\nelse:\n    print(\"[INFO] USE_MAYO_DATA=False, usando ruido simulado\")\n\nprint(f\"\\nMayo LDCT disponible: {MAYO_AVAILABLE}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Importar librerias\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport pydicom\n\n# Procesamiento de imagenes\nfrom skimage.restoration import denoise_tv_chambolle, denoise_bilateral, denoise_nl_means\nfrom skimage.filters import gaussian\nfrom skimage.metrics import peak_signal_noise_ratio as psnr\nfrom skimage.metrics import structural_similarity as ssim\nfrom scipy.ndimage import median_filter\n\n# Deep Learning\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\n# Importar modulos del proyecto\nfrom utils import LUNA16DataLoader, download_luna16\n\n# Configurar dispositivo\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Dispositivo: {device}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n\n# ============================================================\n# CONFIGURAR FUENTE DE DATOS\n# ============================================================\nUSE_SIMULATED_NOISE = not MAYO_AVAILABLE\n\nif MAYO_AVAILABLE:\n    print(\"\\n[OK] Usando datos REALES de Mayo Clinic (NDCT/LDCT)\")\nelse:\n    print(\"\\n[INFO] Mayo no disponible - Usando LUNA16 con ruido SIMULADO\")\n    \n    # Configurar LUNA16\n    DATA_PATH = os.path.join(LUNA16_PATH, 'subset0')\n    ANNOTATIONS_PATH = os.path.join(LUNA16_PATH, 'annotations.csv')\n    \n    # Descargar si no existe\n    if not os.path.exists(DATA_PATH):\n        print(\"[INFO] Descargando LUNA16 subset0...\")\n        download_luna16(subsets=[0], download_dir=LUNA16_PATH)\n    \n    mhd_count = len(list(Path(DATA_PATH).glob(\"*.mhd\"))) if os.path.exists(DATA_PATH) else 0\n    print(f\"  LUNA16 path: {DATA_PATH}\")\n    print(f\"  Scans disponibles: {mhd_count}\")\n\nprint(\"\\nLibrerias importadas\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CARGAR DATOS DE EJEMPLO\n# ============================================================\n\nif USE_SIMULATED_NOISE:\n    # Cargar un escaneo de LUNA16 para demo\n    loader = LUNA16DataLoader(DATA_PATH, ANNOTATIONS_PATH)\n    mhd_files = list(Path(DATA_PATH).glob(\"*.mhd\"))\n    print(f\"Escaneos LUNA16 disponibles: {len(mhd_files)}\")\n    \n    # Cargar escaneo\n    sample_path = str(mhd_files[0])\n    ct_scan, origin, spacing = loader.load_itk_image(sample_path)\n    print(f\"Volumen cargado: {ct_scan.shape}\")\n    print(f\"Spacing: {spacing}\")\n    \n    # Seleccionar un slice central\n    slice_idx = ct_scan.shape[0] // 2\n    original_slice = ct_scan[slice_idx].copy()\n    print(f\"Slice seleccionado: {slice_idx}\")\n    print(f\"Rango HU: [{original_slice.min():.0f}, {original_slice.max():.0f}]\")\nelse:\n    # Cargar un escaneo de Mayo para demo (se hara en celdas posteriores)\n    print(\"[INFO] Datos Mayo se cargaran en seccion dedicada\")\n    original_slice = None"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 2. Modelo de Ruido en CT (Yu et al. 2012)\n\nEl ruido en CT se origina en las **proyecciones** (sinograma), no en la imagen reconstruida.\n\n### Modelo Fisico\n\nPara un rayo de rayos X que atraviesa el objeto:\n\n$$P = -\\ln\\left(\\frac{N}{N_0}\\right) = \\int \\mu(x) \\, dx$$\n\nDonde:\n- $N_0$ = fotones incidentes\n- $N$ = fotones detectados (sigue distribucion Poisson)\n- $P$ = proyeccion (line integral de atenuacion)\n- $\\mu$ = coeficiente de atenuacion\n\n### Simulacion de Dosis Reducida (Eq. 6 del paper)\n\nPara simular una imagen con dosis reducida $a$ (ej: $a=0.25$ para 25%):\n\n$$\\tilde{P}_B \\approx P_A + \\sqrt{\\frac{1-a}{a} \\cdot \\frac{\\exp(P_A)}{N_{0A}}} \\cdot x$$\n\nDonde $x \\sim N(0,1)$ es ruido gaussiano.\n\n### Con Ruido Electronico (Eq. 11)\n\n$$\\tilde{P}_B \\approx P_A + \\sqrt{\\frac{1-a}{a} \\cdot \\frac{\\exp(P_A)}{N_{0A}} \\cdot \\left(1 + \\frac{1+a}{a} \\cdot \\frac{N_e \\cdot \\exp(P_A)}{N_{0A}}\\right)} \\cdot x$$\n\n### Pipeline de Simulacion\n\n```\nImagen NDCT -> Sinograma (Radon) -> +Ruido (Eq.6) -> Reconstruccion (FBP) -> Imagen LDCT\n```\n\n**Referencia**: Yu L, et al. \"Development and Validation of a Practical Lower-Dose-Simulation Tool for Optimizing CT Scan Protocols\". J Comput Assist Tomogr 2012;36:477-487."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# SIMULACION DE RUIDO LDCT - FIEL AL PAPER YU ET AL. 2012\n# ============================================================\n# Referencia: Yu et al. \"Development and Validation of a Practical \n# Lower-Dose-Simulation Tool for Optimizing CT Scan Protocols\"\n# J Comput Assist Tomogr 2012;36:477-487\n#\n# El ruido se simula en el dominio del SINOGRAMA, no en la imagen.\n# ============================================================\n\nfrom skimage.transform import radon, iradon\n\ndef image_to_sinogram(image, theta=None):\n    \"\"\"\n    Convierte imagen CT a sinograma usando transformada de Radon.\n    \n    Args:\n        image: Imagen CT 2D (valores HU o normalizados)\n        theta: Angulos de proyeccion (default: 0-180 grados)\n    \n    Returns:\n        sinogram: Sinograma (proyecciones)\n        theta: Angulos utilizados\n    \"\"\"\n    if theta is None:\n        theta = np.linspace(0., 180., max(image.shape), endpoint=False)\n    \n    sinogram = radon(image, theta=theta, circle=True)\n    return sinogram, theta\n\n\ndef sinogram_to_image(sinogram, theta, output_size=None):\n    \"\"\"\n    Reconstruye imagen desde sinograma usando retroproyeccion filtrada.\n    \n    Args:\n        sinogram: Sinograma\n        theta: Angulos de proyeccion\n        output_size: Tamano de salida (default: automatico)\n    \n    Returns:\n        image: Imagen reconstruida\n    \"\"\"\n    image = iradon(sinogram, theta=theta, output_size=output_size, circle=True)\n    return image\n\n\ndef add_noise_sinogram_domain(image, dose_ratio=0.25, I0=1e5, include_electronic=True, Ne=8.2):\n    \"\"\"\n    Simula LDCT anadiendo ruido en el dominio del sinograma.\n    Implementacion fiel al paper Yu et al. 2012 (Eq. 6 y 11).\n    \n    El modelo de ruido es:\n        P_B = P_A + sqrt((1-a)/a * exp(P_A)/N0_A) * x      (Eq. 6)\n    \n    Con ruido electronico (Eq. 11):\n        P_B = P_A + sqrt((1-a)/a * exp(P_A)/N0_A * (1 + (1+a)/a * Ne*exp(P_A)/N0_A)) * x\n    \n    Args:\n        image: Imagen NDCT original (valores HU)\n        dose_ratio: Ratio de dosis simulada (a). Ej: 0.25 = 25% de dosis original\n        I0: Numero de fotones incidentes (N0) - parametro del escaner\n        include_electronic: Incluir ruido electronico\n        Ne: Ruido electronico equivalente (calibrado en paper como ~8.2)\n    \n    Returns:\n        noisy_image: Imagen LDCT simulada\n        sinogram_noisy: Sinograma con ruido (para visualizacion)\n        sinogram_clean: Sinograma original (para visualizacion)\n    \"\"\"\n    # 1. Normalizar imagen a coeficientes de atenuacion positivos\n    #    HU = 1000 * (mu - mu_water) / mu_water\n    #    => mu/mu_water = HU/1000 + 1\n    #    Usamos valores positivos para el sinograma\n    mu_water = 0.02  # cm^-1 aproximado para agua a ~70 keV\n    \n    # Convertir HU a coeficientes de atenuacion relativos (positivos)\n    # Asumimos que la imagen esta en HU\n    image_hu = image.copy()\n    \n    # Escalar a valores de atenuacion (0 = aire, 1 = agua, >1 = hueso)\n    image_atten = (image_hu / 1000.0) + 1.0\n    image_atten = np.clip(image_atten, 0.001, None)  # Evitar valores negativos/cero\n    \n    # 2. Calcular sinograma (transformada de Radon)\n    #    El sinograma representa la integral de linea de atenuacion\n    sinogram_clean, theta = image_to_sinogram(image_atten)\n    \n    # 3. Convertir a proyecciones P = -ln(N/N0) = integral de mu\n    #    En realidad, radon ya nos da la integral, que es proporcional a P\n    #    P = sum(mu * dx) a lo largo del rayo\n    P_A = sinogram_clean.copy()\n    \n    # Escalar para que los valores sean realistas\n    # (el sinograma de radon no tiene unidades fisicas exactas)\n    P_A = P_A * 0.01  # Factor de escala empirico\n    \n    # 4. Calcular N0_A (fotones incidentes) para cada detector\n    #    Simplificacion: asumimos N0 uniforme (sin bowtie filter)\n    #    En un escaner real, esto varia con el detector (Fig. 3 del paper)\n    N0_A = I0\n    \n    # 5. Aplicar modelo de ruido (Eq. 6 del paper)\n    #    P_B = P_A + sqrt((1-a)/a * exp(P_A)/N0_A) * x\n    a = dose_ratio\n    \n    # Varianza del ruido segun Eq. 6\n    # var = (1-a)/a * exp(P_A) / N0_A\n    exp_P = np.exp(P_A)\n    variance_base = ((1.0 - a) / a) * (exp_P / N0_A)\n    \n    # 6. Incluir ruido electronico si se especifica (Eq. 11)\n    if include_electronic:\n        # var = (1-a)/a * exp(P)/N0 * (1 + (1+a)/a * Ne*exp(P)/N0)\n        electronic_term = 1.0 + ((1.0 + a) / a) * (Ne * exp_P / N0_A)\n        variance = variance_base * electronic_term\n    else:\n        variance = variance_base\n    \n    # Asegurar varianza no negativa\n    variance = np.clip(variance, 0, None)\n    \n    # 7. Generar ruido gaussiano y aplicar\n    x = np.random.randn(*P_A.shape)\n    noise = np.sqrt(variance) * x\n    \n    P_B = P_A + noise\n    \n    # 8. Convertir de vuelta a sinograma para reconstruccion\n    sinogram_noisy = P_B / 0.01  # Deshacer factor de escala\n    \n    # 9. Reconstruir imagen desde sinograma ruidoso\n    image_recon_atten = sinogram_to_image(sinogram_noisy, theta, output_size=image.shape[0])\n    \n    # 10. Convertir de atenuacion a HU\n    noisy_image = (image_recon_atten - 1.0) * 1000.0\n    \n    return noisy_image, sinogram_noisy, sinogram_clean\n\n\ndef add_ldct_noise_yu2012(image, dose_ratio=0.25, I0=1e5):\n    \"\"\"\n    Wrapper simple para simular LDCT segun Yu et al. 2012.\n    \n    Args:\n        image: Imagen NDCT en valores HU\n        dose_ratio: Fraccion de dosis (0.25 = 25% = quarter-dose)\n        I0: Fotones incidentes (ajustar segun nivel de ruido deseado)\n    \n    Returns:\n        noisy_image: Imagen LDCT simulada\n    \"\"\"\n    noisy_image, _, _ = add_noise_sinogram_domain(\n        image, \n        dose_ratio=dose_ratio, \n        I0=I0,\n        include_electronic=True,\n        Ne=8.2\n    )\n    return noisy_image.astype(image.dtype)\n\n\nprint(\"Funciones de ruido implementadas (Yu et al. 2012):\")\nprint(\"  - image_to_sinogram(): Imagen -> Sinograma (Radon)\")\nprint(\"  - sinogram_to_image(): Sinograma -> Imagen (FBP)\")\nprint(\"  - add_noise_sinogram_domain(): Ruido en sinograma (Eq. 6, 11)\")\nprint(\"  - add_ldct_noise_yu2012(): Wrapper simple para LDCT\")\nprint(\"\\nModelo: P_B = P_A + sqrt((1-a)/a * exp(P_A)/N0) * x\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Aplicar simulacion LDCT en dominio del sinograma (Yu et al. 2012)\nif USE_SIMULATED_NOISE and original_slice is not None:\n    print(\"Simulando LDCT en dominio del sinograma...\")\n    print(\"Proceso: Imagen -> Sinograma -> +Ruido -> Reconstruccion\")\n    \n    # Simular diferentes niveles de dosis\n    ldct_25, sino_noisy_25, sino_clean = add_noise_sinogram_domain(\n        original_slice, dose_ratio=0.25, I0=1e5\n    )\n    ldct_50, sino_noisy_50, _ = add_noise_sinogram_domain(\n        original_slice, dose_ratio=0.50, I0=1e5\n    )\n    ldct_10, sino_noisy_10, _ = add_noise_sinogram_domain(\n        original_slice, dose_ratio=0.10, I0=1e5\n    )\n    \n    # Normalizar para visualizacion\n    def normalize_for_display(img, min_hu=-1000, max_hu=400):\n        img_clipped = np.clip(img, min_hu, max_hu)\n        return (img_clipped - min_hu) / (max_hu - min_hu)\n    \n    orig_display = normalize_for_display(original_slice)\n    ldct_25_display = normalize_for_display(ldct_25)\n    ldct_50_display = normalize_for_display(ldct_50)\n    ldct_10_display = normalize_for_display(ldct_10)\n    \n    # Para compatibilidad con celdas posteriores\n    noisy_ldct = ldct_25\n    ldct_display = ldct_25_display\n    \n    print(\"[OK] Simulacion LDCT completada\")\n    print(f\"  - 50% dosis: PSNR = {psnr(orig_display, ldct_50_display, data_range=1.0):.2f} dB\")\n    print(f\"  - 25% dosis: PSNR = {psnr(orig_display, ldct_25_display, data_range=1.0):.2f} dB\")\n    print(f\"  - 10% dosis: PSNR = {psnr(orig_display, ldct_10_display, data_range=1.0):.2f} dB\")\nelse:\n    print(\"[INFO] Usando datos reales Mayo - no se simula ruido\")\n    \n    def normalize_for_display(img, min_hu=-1000, max_hu=400):\n        img_clipped = np.clip(img, min_hu, max_hu)\n        return (img_clipped - min_hu) / (max_hu - min_hu)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualizar el proceso de simulacion LDCT en dominio del sinograma\nif USE_SIMULATED_NOISE and original_slice is not None:\n    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n    \n    # Fila 1: Proceso de simulacion\n    axes[0, 0].imshow(orig_display, cmap='bone')\n    axes[0, 0].set_title('1. Imagen Original\\n(NDCT)', fontsize=12)\n    axes[0, 0].axis('off')\n    \n    axes[0, 1].imshow(sino_clean, cmap='bone', aspect='auto')\n    axes[0, 1].set_title('2. Sinograma\\n(Radon Transform)', fontsize=12)\n    axes[0, 1].set_xlabel('Angulo')\n    axes[0, 1].set_ylabel('Detector')\n    \n    # Diferencia de sinogramas (ruido anadido)\n    sino_diff = sino_noisy_25 - sino_clean\n    axes[0, 2].imshow(sino_diff, cmap='RdBu', aspect='auto', \n                      vmin=-np.percentile(np.abs(sino_diff), 99),\n                      vmax=np.percentile(np.abs(sino_diff), 99))\n    axes[0, 2].set_title('3. Ruido Anadido\\n(Eq. 6 Yu et al.)', fontsize=12)\n    axes[0, 2].set_xlabel('Angulo')\n    axes[0, 2].set_ylabel('Detector')\n    \n    axes[0, 3].imshow(ldct_25_display, cmap='bone')\n    axes[0, 3].set_title('4. LDCT Reconstruido\\n(25% dosis)', fontsize=12)\n    axes[0, 3].axis('off')\n    \n    # Fila 2: Comparacion de niveles de dosis\n    axes[1, 0].imshow(orig_display, cmap='bone')\n    axes[1, 0].set_title('Original (100% dosis)', fontsize=12)\n    axes[1, 0].axis('off')\n    \n    axes[1, 1].imshow(ldct_50_display, cmap='bone')\n    psnr_50 = psnr(orig_display, ldct_50_display, data_range=1.0)\n    axes[1, 1].set_title(f'50% dosis\\nPSNR: {psnr_50:.1f} dB', fontsize=12)\n    axes[1, 1].axis('off')\n    \n    axes[1, 2].imshow(ldct_25_display, cmap='bone')\n    psnr_25 = psnr(orig_display, ldct_25_display, data_range=1.0)\n    axes[1, 2].set_title(f'25% dosis\\nPSNR: {psnr_25:.1f} dB', fontsize=12)\n    axes[1, 2].axis('off')\n    \n    axes[1, 3].imshow(ldct_10_display, cmap='bone')\n    psnr_10 = psnr(orig_display, ldct_10_display, data_range=1.0)\n    axes[1, 3].set_title(f'10% dosis\\nPSNR: {psnr_10:.1f} dB', fontsize=12)\n    axes[1, 3].axis('off')\n    \n    plt.suptitle('Simulacion LDCT en Dominio del Sinograma (Yu et al. 2012)', fontsize=14)\n    plt.tight_layout()\n    plt.show()\n    \n    # Visualizar zoom\n    fig2, axes2 = plt.subplots(1, 4, figsize=(16, 4))\n    y1, y2, x1, x2 = 200, 300, 200, 300\n    \n    axes2[0].imshow(orig_display[y1:y2, x1:x2], cmap='bone')\n    axes2[0].set_title('Original', fontsize=12)\n    axes2[0].axis('off')\n    \n    axes2[1].imshow(ldct_50_display[y1:y2, x1:x2], cmap='bone')\n    axes2[1].set_title('50% dosis', fontsize=12)\n    axes2[1].axis('off')\n    \n    axes2[2].imshow(ldct_25_display[y1:y2, x1:x2], cmap='bone')\n    axes2[2].set_title('25% dosis', fontsize=12)\n    axes2[2].axis('off')\n    \n    axes2[3].imshow(ldct_10_display[y1:y2, x1:x2], cmap='bone')\n    axes2[3].set_title('10% dosis', fontsize=12)\n    axes2[3].axis('off')\n    \n    plt.suptitle('Zoom - Detalle del Ruido', fontsize=14)\n    plt.tight_layout()\n    plt.show()\n    \nelse:\n    print(\"[SKIP] Visualizacion de ruido simulado - usando datos reales Mayo\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Calcular metricas de calidad (solo ruido simulado)\nif USE_SIMULATED_NOISE and original_slice is not None:\n    print(\"Metricas de Calidad de Imagen (respecto al original):\")\n    print(\"=\"*60)\n    \n    metrics = []\n    for name, noisy in [('Gaussiano', gauss_display), \n                        ('Poisson', poisson_display), \n                        ('LDCT Sim.', ldct_display)]:\n        psnr_val = psnr(orig_display, noisy, data_range=1.0)\n        ssim_val = ssim(orig_display, noisy, data_range=1.0)\n        mse_val = np.mean((orig_display - noisy)**2)\n        \n        metrics.append({\n            'Tipo': name,\n            'PSNR (dB)': f'{psnr_val:.2f}',\n            'SSIM': f'{ssim_val:.4f}',\n            'MSE': f'{mse_val:.6f}'\n        })\n        \n        print(f\"\\n{name}:\")\n        print(f\"  PSNR: {psnr_val:.2f} dB\")\n        print(f\"  SSIM: {ssim_val:.4f}\")\n        print(f\"  MSE:  {mse_val:.6f}\")\n    \n    print(\"\\n\" + \"=\"*60)\n    metrics_df = pd.DataFrame(metrics)\n    print(metrics_df.to_string(index=False))\nelse:\n    print(\"[SKIP] Metricas de ruido simulado - usando datos reales Mayo\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Variación del Nivel de Ruido\n",
    "\n",
    "Exploramos cómo diferentes niveles de dosis afectan la calidad de imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Simular diferentes niveles de dosis (solo con ruido simulado)\nif USE_SIMULATED_NOISE and original_slice is not None:\n    dose_ratios = [1.0, 0.5, 0.25, 0.125, 0.0625]  # 100%, 50%, 25%, 12.5%, 6.25%\n    dose_labels = ['100%', '50%', '25%', '12.5%', '6.25%']\n\n    fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n\n    for i, (dose, label) in enumerate(zip(dose_ratios, dose_labels)):\n        if dose == 1.0:\n            noisy = original_slice.copy()\n        else:\n            noisy = add_ct_realistic_noise(original_slice, dose_ratio=dose)\n        \n        noisy_display = normalize_for_display(noisy)\n        \n        # Imagen completa\n        axes[0, i].imshow(noisy_display, cmap='bone')\n        axes[0, i].set_title(f'Dosis: {label}', fontsize=12)\n        axes[0, i].axis('off')\n        \n        # Zoom\n        axes[1, i].imshow(noisy_display[200:300, 200:300], cmap='bone')\n        \n        # Calcular PSNR solo para imagenes con ruido\n        if dose < 1.0:\n            psnr_val = psnr(orig_display, noisy_display, data_range=1.0)\n            axes[1, i].set_title(f'PSNR: {psnr_val:.1f} dB', fontsize=11)\n        else:\n            axes[1, i].set_title('Referencia', fontsize=11)\n        axes[1, i].axis('off')\n\n    plt.suptitle('Efecto del Nivel de Dosis en la Calidad de Imagen CT', fontsize=14)\n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"[SKIP] Visualizacion de niveles de dosis - usando datos reales Mayo\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Técnicas Clásicas de Denoising\n",
    "\n",
    "Antes de deep learning, se usaban filtros clásicos:\n",
    "\n",
    "| Técnica | Descripción | Pros | Contras |\n",
    "|---------|-------------|------|----------|\n",
    "| Gaussiano | Suavizado isotrópico | Rápido | Pierde bordes |\n",
    "| Mediana | Filtro no lineal | Preserva bordes | Pierde detalles finos |\n",
    "| Bilateral | Preserva bordes | Buenos resultados | Lento |\n",
    "| TV (Total Variation) | Minimiza variación | Preserva bordes | Efecto \"cartoon\" |\n",
    "| NLM (Non-Local Means) | Usa parches similares | Muy buenos resultados | Muy lento |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_classical_denoising(image_normalized):\n",
    "    \"\"\"\n",
    "    Aplica diferentes técnicas clásicas de denoising\n",
    "    \n",
    "    Args:\n",
    "        image_normalized: Imagen normalizada [0, 1]\n",
    "    \n",
    "    Returns:\n",
    "        dict: Diccionario con resultados de cada técnica\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # 1. Filtro Gaussiano\n",
    "    results['Gaussiano'] = gaussian(image_normalized, sigma=1.5)\n",
    "    \n",
    "    # 2. Filtro Mediana\n",
    "    results['Mediana'] = median_filter(image_normalized, size=3)\n",
    "    \n",
    "    # 3. Filtro Bilateral\n",
    "    results['Bilateral'] = denoise_bilateral(\n",
    "        image_normalized, \n",
    "        sigma_color=0.1, \n",
    "        sigma_spatial=5,\n",
    "        channel_axis=None\n",
    "    )\n",
    "    \n",
    "    # 4. Total Variation\n",
    "    results['TV'] = denoise_tv_chambolle(image_normalized, weight=0.1)\n",
    "    \n",
    "    # 5. Non-Local Means (versión rápida)\n",
    "    results['NLM'] = denoise_nl_means(\n",
    "        image_normalized,\n",
    "        h=0.1,\n",
    "        patch_size=5,\n",
    "        patch_distance=6,\n",
    "        channel_axis=None\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"Funciones de denoising clásico definidas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Aplicar denoising a imagen LDCT simulada (solo con ruido simulado)\nif USE_SIMULATED_NOISE and original_slice is not None:\n    print(\"Aplicando tecnicas de denoising...\")\n    print(\"(Esto puede tomar unos segundos)\")\n\n    denoised_results = apply_classical_denoising(ldct_display)\n\n    print(\"\\n[OK] Denoising completado!\")\nelse:\n    denoised_results = None\n    print(\"[SKIP] Denoising clasico - usando datos reales Mayo\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualizar resultados de denoising (solo con ruido simulado)\nif USE_SIMULATED_NOISE and denoised_results is not None:\n    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n\n    # Fila 1: Imagenes completas\n    axes[0, 0].imshow(orig_display, cmap='bone')\n    axes[0, 0].set_title('Original (NDCT)', fontsize=12)\n    axes[0, 0].axis('off')\n\n    axes[0, 1].imshow(ldct_display, cmap='bone')\n    psnr_noisy = psnr(orig_display, ldct_display, data_range=1.0)\n    axes[0, 1].set_title(f'LDCT Simulado\\nPSNR: {psnr_noisy:.1f} dB', fontsize=12)\n    axes[0, 1].axis('off')\n\n    # Mejores tecnicas\n    best_techniques = ['Bilateral', 'NLM']\n    for i, tech in enumerate(best_techniques):\n        denoised = denoised_results[tech]\n        psnr_val = psnr(orig_display, denoised, data_range=1.0)\n        axes[0, i+2].imshow(denoised, cmap='bone')\n        axes[0, i+2].set_title(f'{tech}\\nPSNR: {psnr_val:.1f} dB', fontsize=12)\n        axes[0, i+2].axis('off')\n\n    # Fila 2: Zoom\n    y1, y2, x1, x2 = 200, 300, 200, 300\n\n    axes[1, 0].imshow(orig_display[y1:y2, x1:x2], cmap='bone')\n    axes[1, 0].set_title('Zoom Original', fontsize=12)\n    axes[1, 0].axis('off')\n\n    axes[1, 1].imshow(ldct_display[y1:y2, x1:x2], cmap='bone')\n    axes[1, 1].set_title('Zoom LDCT', fontsize=12)\n    axes[1, 1].axis('off')\n\n    for i, tech in enumerate(best_techniques):\n        denoised = denoised_results[tech]\n        axes[1, i+2].imshow(denoised[y1:y2, x1:x2], cmap='bone')\n        axes[1, i+2].set_title(f'Zoom {tech}', fontsize=12)\n        axes[1, i+2].axis('off')\n\n    plt.suptitle('Comparacion de Tecnicas de Denoising', fontsize=14)\n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"[SKIP] Visualizacion de denoising clasico - usando datos reales Mayo\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Tabla comparativa de todas las tecnicas (solo con ruido simulado)\nif USE_SIMULATED_NOISE and denoised_results is not None:\n    print(\"Comparacion de Tecnicas de Denoising\")\n    print(\"=\"*65)\n\n    psnr_noisy = psnr(orig_display, ldct_display, data_range=1.0)\n    \n    comparison = []\n    comparison.append({\n        'Tecnica': 'LDCT (con ruido)',\n        'PSNR (dB)': psnr_noisy,\n        'SSIM': ssim(orig_display, ldct_display, data_range=1.0)\n    })\n\n    for tech, denoised in denoised_results.items():\n        comparison.append({\n            'Tecnica': tech,\n            'PSNR (dB)': psnr(orig_display, denoised, data_range=1.0),\n            'SSIM': ssim(orig_display, denoised, data_range=1.0)\n        })\n\n    comparison_df = pd.DataFrame(comparison)\n    comparison_df['PSNR (dB)'] = comparison_df['PSNR (dB)'].round(2)\n    comparison_df['SSIM'] = comparison_df['SSIM'].round(4)\n\n    # Ordenar por PSNR\n    comparison_df = comparison_df.sort_values('PSNR (dB)', ascending=False)\n    print(comparison_df.to_string(index=False))\n\n    print(\"\\n\" + \"=\"*65)\n    print(\"Mayor PSNR y SSIM = Mejor calidad de imagen\")\nelse:\n    comparison_df = None\n    print(\"[SKIP] Tabla comparativa - usando datos reales Mayo\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Denoising con Deep Learning: DnCNN\n",
    "\n",
    "**DnCNN** (Denoising Convolutional Neural Network) es una arquitectura clásica para denoising:\n",
    "\n",
    "- Aprende el **residuo** (ruido) en lugar de la imagen limpia\n",
    "- Usa batch normalization y ReLU\n",
    "- Típicamente 17-20 capas convolucionales\n",
    "\n",
    "$$\\hat{x} = y - f(y; \\theta)$$\n",
    "\n",
    "donde $y$ es la imagen ruidosa, $f$ predice el ruido, y $\\hat{x}$ es la imagen denoised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DnCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    DnCNN para denoising de imágenes CT\n",
    "    \n",
    "    Arquitectura:\n",
    "    - Conv + ReLU (primera capa)\n",
    "    - (Conv + BN + ReLU) x (depth-2) capas intermedias\n",
    "    - Conv (última capa)\n",
    "    \n",
    "    El modelo predice el residuo (ruido) que se resta de la entrada.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=1, out_channels=1, num_features=64, depth=17):\n",
    "        super(DnCNN, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        \n",
    "        # Primera capa: Conv + ReLU\n",
    "        layers.append(nn.Conv2d(in_channels, num_features, kernel_size=3, padding=1, bias=False))\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "        \n",
    "        # Capas intermedias: Conv + BN + ReLU\n",
    "        for _ in range(depth - 2):\n",
    "            layers.append(nn.Conv2d(num_features, num_features, kernel_size=3, padding=1, bias=False))\n",
    "            layers.append(nn.BatchNorm2d(num_features))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        \n",
    "        # Última capa: Conv (sin activación)\n",
    "        layers.append(nn.Conv2d(num_features, out_channels, kernel_size=3, padding=1, bias=False))\n",
    "        \n",
    "        self.dncnn = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Predice el residuo y lo resta de la entrada\"\"\"\n",
    "        residual = self.dncnn(x)\n",
    "        return x - residual  # Imagen denoised\n",
    "\n",
    "\n",
    "# Crear modelo\n",
    "model_dncnn = DnCNN(in_channels=1, out_channels=1, num_features=64, depth=17).to(device)\n",
    "\n",
    "print(\"DnCNN creado\")\n",
    "print(f\"Parámetros totales: {sum(p.numel() for p in model_dncnn.parameters()):,}\")\n",
    "print(f\"Dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Dataset para entrenamiento con ruido simulado en dominio del sinograma\nif USE_SIMULATED_NOISE:\n    class CTDenoisingDataset(Dataset):\n        \"\"\"\n        Dataset para entrenamiento de denoising en CT.\n        \n        Genera pares (LDCT, NDCT) simulando ruido en el dominio\n        del sinograma segun Yu et al. 2012.\n        \"\"\"\n        def __init__(self, data_path, annotations_path, patch_size=64, \n                     num_patches_per_scan=50, dose_ratio=0.25, I0=1e5):\n            self.patch_size = patch_size\n            self.num_patches = num_patches_per_scan\n            self.dose_ratio = dose_ratio\n            self.I0 = I0\n            \n            # Cargar datos\n            self.loader = LUNA16DataLoader(data_path, annotations_path)\n            self.mhd_files = list(Path(data_path).glob(\"*.mhd\"))\n            \n            # Cache de slices (pares NDCT, LDCT)\n            self._pairs_cache = []\n            self._load_and_simulate()\n        \n        def _load_and_simulate(self):\n            \"\"\"Carga slices y simula LDCT en dominio del sinograma\"\"\"\n            print(\"Cargando slices y simulando LDCT (Yu et al. 2012)...\")\n            print(\"  Proceso: Imagen -> Sinograma -> +Ruido -> Reconstruccion\")\n            \n            max_scans = min(5, len(self.mhd_files))\n            \n            for mhd_file in tqdm(self.mhd_files[:max_scans], desc=\"Procesando scans\"):\n                ct_scan, _, _ = self.loader.load_itk_image(str(mhd_file))\n                \n                # Tomar slices centrales\n                start_slice = ct_scan.shape[0] // 4\n                end_slice = 3 * ct_scan.shape[0] // 4\n                \n                for slice_idx in range(start_slice, end_slice, 10):  # Cada 10 slices\n                    ndct_slice = ct_scan[slice_idx]\n                    \n                    # Simular LDCT en dominio del sinograma\n                    ldct_slice = add_ldct_noise_yu2012(\n                        ndct_slice, \n                        dose_ratio=self.dose_ratio,\n                        I0=self.I0\n                    )\n                    \n                    # Normalizar ambas\n                    ndct_norm = self.loader.normalize_hu(ndct_slice, -1000, 400)\n                    ldct_norm = self.loader.normalize_hu(ldct_slice, -1000, 400)\n                    \n                    self._pairs_cache.append((ndct_norm, ldct_norm))\n            \n            print(f\"[OK] Pares NDCT/LDCT generados: {len(self._pairs_cache)}\")\n        \n        def __len__(self):\n            return len(self._pairs_cache) * self.num_patches\n        \n        def _extract_random_patch(self, ndct, ldct):\n            \"\"\"Extrae patch aleatorio del mismo lugar en ambas imagenes\"\"\"\n            h, w = ndct.shape\n            \n            max_y = h - self.patch_size\n            max_x = w - self.patch_size\n            \n            if max_y <= 0 or max_x <= 0:\n                return ndct[:self.patch_size, :self.patch_size], \\\n                       ldct[:self.patch_size, :self.patch_size]\n            \n            y = np.random.randint(0, max_y)\n            x = np.random.randint(0, max_x)\n            \n            return ndct[y:y+self.patch_size, x:x+self.patch_size], \\\n                   ldct[y:y+self.patch_size, x:x+self.patch_size]\n        \n        def __getitem__(self, idx):\n            # Seleccionar par\n            pair_idx = idx // self.num_patches\n            ndct_slice, ldct_slice = self._pairs_cache[pair_idx]\n            \n            # Extraer patch aleatorio\n            ndct_patch, ldct_patch = self._extract_random_patch(ndct_slice, ldct_slice)\n            \n            # Clip para asegurar rango valido\n            ndct_patch = np.clip(ndct_patch, 0, 1)\n            ldct_patch = np.clip(ldct_patch, 0, 1)\n            \n            # Convertir a tensores\n            ndct_tensor = torch.FloatTensor(ndct_patch).unsqueeze(0)\n            ldct_tensor = torch.FloatTensor(ldct_patch).unsqueeze(0)\n            \n            # Retornar (ruidosa, limpia)\n            return ldct_tensor, ndct_tensor\n\n    print(\"[OK] Dataset con ruido en sinograma definido (Yu et al. 2012)\")\nelse:\n    print(\"[INFO] Usando datos reales Mayo - dataset simulado no necesario\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Crear dataset y dataloader (solo ruido simulado)\nif USE_SIMULATED_NOISE:\n    denoise_dataset = CTDenoisingDataset(\n        DATA_PATH, \n        ANNOTATIONS_PATH,\n        patch_size=64,\n        num_patches_per_scan=100,\n        dose_ratio=0.25\n    )\n\n    denoise_loader = DataLoader(\n        denoise_dataset, \n        batch_size=16, \n        shuffle=True,\n        num_workers=0\n    )\n\n    print(f\"\\nDataset size: {len(denoise_dataset)}\")\n    print(f\"Batches: {len(denoise_loader)}\")\nelse:\n    denoise_dataset = None\n    denoise_loader = None\n    print(\"[INFO] Dataset simulado no creado - se usara Mayo\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualizar ejemplos del dataset (solo ruido simulado)\nif USE_SIMULATED_NOISE and denoise_loader is not None:\n    noisy_batch, clean_batch = next(iter(denoise_loader))\n\n    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n\n    for i in range(4):\n        axes[0, i].imshow(noisy_batch[i, 0].numpy(), cmap='bone')\n        axes[0, i].set_title('Ruidosa (LDCT)', fontsize=11)\n        axes[0, i].axis('off')\n        \n        axes[1, i].imshow(clean_batch[i, 0].numpy(), cmap='bone')\n        axes[1, i].set_title('Limpia (NDCT)', fontsize=11)\n        axes[1, i].axis('off')\n\n    plt.suptitle('Ejemplos del Dataset de Denoising (Pares Ruidosa/Limpia)', fontsize=14)\n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"[SKIP] Visualizacion de dataset simulado - se usara Mayo\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Entrenamiento del Modelo DnCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_denoiser(model, dataloader, epochs=10, lr=1e-3):\n",
    "    \"\"\"\n",
    "    Entrena el modelo de denoising\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo DnCNN\n",
    "        dataloader: DataLoader con pares (ruidosa, limpia)\n",
    "        epochs: Número de épocas\n",
    "        lr: Learning rate\n",
    "    \n",
    "    Returns:\n",
    "        history: Diccionario con historial de entrenamiento\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "    \n",
    "    history = {'loss': [], 'psnr': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_psnr = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        pbar = tqdm(dataloader, desc=f'Época {epoch+1}/{epochs}')\n",
    "        \n",
    "        for noisy, clean in pbar:\n",
    "            noisy = noisy.to(device)\n",
    "            clean = clean.to(device)\n",
    "            \n",
    "            # Forward\n",
    "            optimizer.zero_grad()\n",
    "            denoised = model(noisy)\n",
    "            loss = criterion(denoised, clean)\n",
    "            \n",
    "            # Backward\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Métricas\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # Calcular PSNR\n",
    "            with torch.no_grad():\n",
    "                mse = F.mse_loss(denoised, clean)\n",
    "                batch_psnr = 10 * torch.log10(1.0 / mse)\n",
    "                epoch_psnr += batch_psnr.item()\n",
    "            \n",
    "            num_batches += 1\n",
    "            pbar.set_postfix({'Loss': f'{loss.item():.6f}', 'PSNR': f'{batch_psnr.item():.2f}'})\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        avg_loss = epoch_loss / num_batches\n",
    "        avg_psnr = epoch_psnr / num_batches\n",
    "        \n",
    "        history['loss'].append(avg_loss)\n",
    "        history['psnr'].append(avg_psnr)\n",
    "        \n",
    "        print(f'Época {epoch+1}: Loss = {avg_loss:.6f}, PSNR = {avg_psnr:.2f} dB')\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "print(\"Función de entrenamiento definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Entrenar el modelo (solo ruido simulado)\nif USE_SIMULATED_NOISE and denoise_loader is not None:\n    print(\"Iniciando entrenamiento con ruido simulado...\")\n    print(\"=\"*60)\n\n    history = train_denoiser(model_dncnn, denoise_loader, epochs=5, lr=1e-3)\n\n    print(\"\\n\" + \"=\"*60)\n    print(\"[OK] Entrenamiento completado!\")\nelse:\n    history = None\n    print(\"[INFO] Entrenamiento con ruido simulado omitido\")\n    print(\"       Se entrenara con datos reales Mayo en celdas posteriores\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualizar historial de entrenamiento (solo ruido simulado)\nif history is not None:\n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n    # Loss\n    axes[0].plot(history['loss'], 'b-o', linewidth=2, markersize=8)\n    axes[0].set_xlabel('Epoca', fontsize=12)\n    axes[0].set_ylabel('Loss (MSE)', fontsize=12)\n    axes[0].set_title('Perdida durante Entrenamiento', fontsize=14)\n    axes[0].grid(True, alpha=0.3)\n\n    # PSNR\n    axes[1].plot(history['psnr'], 'g-o', linewidth=2, markersize=8)\n    axes[1].set_xlabel('Epoca', fontsize=12)\n    axes[1].set_ylabel('PSNR (dB)', fontsize=12)\n    axes[1].set_title('PSNR durante Entrenamiento', fontsize=14)\n    axes[1].grid(True, alpha=0.3)\n\n    plt.suptitle('Historial de Entrenamiento DnCNN', fontsize=14)\n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"[SKIP] Historial de entrenamiento - se mostrara despues de entrenar con Mayo\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def evaluate_denoiser(model, image_clean_hu, dose_ratio=0.25, I0=1e5):\n    \"\"\"\n    Evalua el modelo de denoising en una imagen.\n    Usa simulacion de ruido en dominio del sinograma (Yu et al. 2012).\n    \n    Args:\n        model: Modelo entrenado\n        image_clean_hu: Imagen limpia en valores HU\n        dose_ratio: Ratio de dosis para simular LDCT\n        I0: Fotones incidentes\n    \n    Returns:\n        dict: Resultados con imagenes y metricas\n    \"\"\"\n    model.eval()\n    \n    # Simular LDCT en dominio del sinograma\n    noisy_hu = add_ldct_noise_yu2012(image_clean_hu, dose_ratio=dose_ratio, I0=I0)\n    \n    # Normalizar para el modelo\n    def normalize(img):\n        img_clipped = np.clip(img, -1000, 400)\n        return (img_clipped - (-1000)) / (400 - (-1000))\n    \n    clean = normalize(image_clean_hu)\n    noisy = normalize(noisy_hu)\n    \n    # Preparar tensor\n    noisy_tensor = torch.FloatTensor(noisy).unsqueeze(0).unsqueeze(0).to(device)\n    \n    # Inferencia\n    with torch.no_grad():\n        denoised_tensor = model(noisy_tensor)\n    \n    denoised = denoised_tensor.squeeze().cpu().numpy()\n    denoised = np.clip(denoised, 0, 1)\n    \n    # Calcular metricas\n    psnr_noisy = psnr(clean, noisy, data_range=1.0)\n    psnr_denoised = psnr(clean, denoised, data_range=1.0)\n    \n    ssim_noisy = ssim(clean, noisy, data_range=1.0)\n    ssim_denoised = ssim(clean, denoised, data_range=1.0)\n    \n    return {\n        'clean': clean,\n        'noisy': noisy,\n        'denoised': denoised,\n        'psnr_noisy': psnr_noisy,\n        'psnr_denoised': psnr_denoised,\n        'ssim_noisy': ssim_noisy,\n        'ssim_denoised': ssim_denoised,\n        'psnr_gain': psnr_denoised - psnr_noisy,\n        'ssim_gain': ssim_denoised - ssim_noisy\n    }\n\n\nprint(\"Funcion de evaluacion definida (usa ruido en sinograma)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Evaluar en imagen de prueba (solo ruido simulado)\nif USE_SIMULATED_NOISE and original_slice is not None:\n    results = evaluate_denoiser(model_dncnn, orig_display, dose_ratio=0.25)\n\n    print(\"Metricas de Evaluacion:\")\n    print(\"=\"*50)\n    print(f\"\\nImagen LDCT (con ruido):\")\n    print(f\"  PSNR: {results['psnr_noisy']:.2f} dB\")\n    print(f\"  SSIM: {results['ssim_noisy']:.4f}\")\n\n    print(f\"\\nImagen Denoised (DnCNN):\")\n    print(f\"  PSNR: {results['psnr_denoised']:.2f} dB (+{results['psnr_gain']:.2f} dB)\")\n    print(f\"  SSIM: {results['ssim_denoised']:.4f} (+{results['ssim_gain']:.4f})\")\nelse:\n    results = None\n    print(\"[INFO] Evaluacion con ruido simulado omitida\")\n    print(\"       Se evaluara despues de entrenar con datos Mayo\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualizar resultados de denoising con DnCNN (solo ruido simulado)\nif results is not None:\n    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n\n    # Fila 1: Imagenes completas\n    axes[0, 0].imshow(results['clean'], cmap='bone')\n    axes[0, 0].set_title('Original (NDCT)', fontsize=12)\n    axes[0, 0].axis('off')\n\n    axes[0, 1].imshow(results['noisy'], cmap='bone')\n    axes[0, 1].set_title(f'LDCT Simulado\\nPSNR: {results[\"psnr_noisy\"]:.1f} dB', fontsize=12)\n    axes[0, 1].axis('off')\n\n    axes[0, 2].imshow(results['denoised'], cmap='bone')\n    axes[0, 2].set_title(f'DnCNN Denoised\\nPSNR: {results[\"psnr_denoised\"]:.1f} dB', fontsize=12)\n    axes[0, 2].axis('off')\n\n    # Diferencia (residuo aprendido)\n    residual = np.abs(results['noisy'] - results['denoised'])\n    axes[0, 3].imshow(residual, cmap='hot')\n    axes[0, 3].set_title('Ruido Removido\\n(Residuo)', fontsize=12)\n    axes[0, 3].axis('off')\n\n    # Fila 2: Zoom\n    y1, y2, x1, x2 = 200, 300, 200, 300\n\n    axes[1, 0].imshow(results['clean'][y1:y2, x1:x2], cmap='bone')\n    axes[1, 0].set_title('Zoom Original', fontsize=12)\n    axes[1, 0].axis('off')\n\n    axes[1, 1].imshow(results['noisy'][y1:y2, x1:x2], cmap='bone')\n    axes[1, 1].set_title('Zoom LDCT', fontsize=12)\n    axes[1, 1].axis('off')\n\n    axes[1, 2].imshow(results['denoised'][y1:y2, x1:x2], cmap='bone')\n    axes[1, 2].set_title('Zoom DnCNN', fontsize=12)\n    axes[1, 2].axis('off')\n\n    axes[1, 3].imshow(residual[y1:y2, x1:x2], cmap='hot')\n    axes[1, 3].set_title('Zoom Residuo', fontsize=12)\n    axes[1, 3].axis('off')\n\n    plt.suptitle('Resultados de Denoising con DnCNN', fontsize=14)\n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"[SKIP] Visualizacion de resultados - se mostrara despues de entrenar con Mayo\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Comparación: Clásico vs Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Comparacion final de todas las tecnicas (solo ruido simulado)\nif results is not None and denoised_results is not None:\n    print(\"Comparacion Final: Clasico vs Deep Learning\")\n    print(\"=\"*65)\n\n    # Aplicar denoising clasico a la misma imagen ruidosa\n    classical_on_same = apply_classical_denoising(results['noisy'])\n\n    final_comparison = []\n\n    # LDCT (referencia)\n    final_comparison.append({\n        'Tecnica': 'LDCT (sin procesar)',\n        'Tipo': 'Referencia',\n        'PSNR (dB)': results['psnr_noisy'],\n        'SSIM': results['ssim_noisy']\n    })\n\n    # Tecnicas clasicas\n    for tech, denoised in classical_on_same.items():\n        final_comparison.append({\n            'Tecnica': tech,\n            'Tipo': 'Clasico',\n            'PSNR (dB)': psnr(results['clean'], denoised, data_range=1.0),\n            'SSIM': ssim(results['clean'], denoised, data_range=1.0)\n        })\n\n    # DnCNN\n    final_comparison.append({\n        'Tecnica': 'DnCNN',\n        'Tipo': 'Deep Learning',\n        'PSNR (dB)': results['psnr_denoised'],\n        'SSIM': results['ssim_denoised']\n    })\n\n    # Crear DataFrame y ordenar\n    final_df = pd.DataFrame(final_comparison)\n    final_df['PSNR (dB)'] = final_df['PSNR (dB)'].round(2)\n    final_df['SSIM'] = final_df['SSIM'].round(4)\n    final_df = final_df.sort_values('PSNR (dB)', ascending=False)\n\n    print(final_df.to_string(index=False))\n    print(\"\\n\" + \"=\"*65)\nelse:\n    final_df = None\n    print(\"[SKIP] Comparacion final - se mostrara despues de entrenar con Mayo\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Grafico de barras comparativo (solo ruido simulado)\nif final_df is not None and results is not None:\n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n    # Ordenar por PSNR para visualizacion\n    df_sorted = final_df.sort_values('PSNR (dB)', ascending=True)\n\n    # Colores por tipo\n    colors = ['gray' if t == 'Referencia' else 'steelblue' if t == 'Clasico' else 'coral' \n              for t in df_sorted['Tipo']]\n\n    # PSNR\n    axes[0].barh(df_sorted['Tecnica'], df_sorted['PSNR (dB)'], color=colors)\n    axes[0].set_xlabel('PSNR (dB)', fontsize=12)\n    axes[0].set_title('Comparacion de PSNR', fontsize=14)\n    axes[0].axvline(x=results['psnr_noisy'], color='red', linestyle='--', alpha=0.5, label='LDCT')\n    axes[0].grid(True, alpha=0.3, axis='x')\n\n    # SSIM\n    axes[1].barh(df_sorted['Tecnica'], df_sorted['SSIM'], color=colors)\n    axes[1].set_xlabel('SSIM', fontsize=12)\n    axes[1].set_title('Comparacion de SSIM', fontsize=14)\n    axes[1].axvline(x=results['ssim_noisy'], color='red', linestyle='--', alpha=0.5, label='LDCT')\n    axes[1].grid(True, alpha=0.3, axis='x')\n\n    # Leyenda\n    from matplotlib.patches import Patch\n    legend_elements = [\n        Patch(facecolor='gray', label='Referencia'),\n        Patch(facecolor='steelblue', label='Clasico'),\n        Patch(facecolor='coral', label='Deep Learning')\n    ]\n    fig.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(0.98, 0.98))\n\n    plt.suptitle('Comparacion de Tecnicas de Denoising', fontsize=14)\n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"[SKIP] Grafico comparativo - se mostrara despues de entrenar con Mayo\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Guardar Modelo Entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Guardar pesos del modelo\n# weights_dir ya esta definido en celda inicial (Drive en Colab, local en PC)\n\nmodel_path = os.path.join(weights_dir, 'dncnn_denoising.pth')\n\nif USE_SIMULATED_NOISE:\n    torch.save(model_dncnn.state_dict(), model_path)\n    print(f\"[OK] Modelo guardado en: {model_path}\")\n    print(f\"    Tamano: {os.path.getsize(model_path) / 1024 / 1024:.2f} MB\")\nelse:\n    print(\"[INFO] Modelo se guardara despues de entrenar con datos Mayo\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Funcion para cargar modelo guardado\ndef load_denoiser(weights_path, device='cuda'):\n    \"\"\"\n    Carga un modelo DnCNN entrenado\n    \n    Args:\n        weights_path: Ruta al archivo .pth\n        device: Dispositivo ('cuda' o 'cpu')\n    \n    Returns:\n        model: Modelo cargado listo para inferencia\n    \"\"\"\n    model = DnCNN(in_channels=1, out_channels=1, num_features=64, depth=17)\n    model.load_state_dict(torch.load(weights_path, map_location=device))\n    model.to(device)\n    model.eval()\n    return model\n\n\n# Verificar que se puede cargar (solo si se entreno con ruido simulado)\nif USE_SIMULATED_NOISE and os.path.exists(model_path):\n    model_loaded = load_denoiser(model_path, device)\n    print(\"[OK] Modelo cargado correctamente!\")\nelse:\n    model_loaded = None\n    print(\"[INFO] Modelo se cargara despues de entrenar con Mayo\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Dataset Mayo Clinic LDCT (TCIA) - Datos Reales\n",
    "\n",
    "El **AAPM Low Dose CT Grand Challenge** proporciona pares reales de imágenes NDCT/LDCT del Mayo Clinic.\n",
    "\n",
    "### Información del Dataset:\n",
    "\n",
    "| Aspecto | Detalle |\n",
    "|---------|---------|\n",
    "| **Nombre** | LDCT-and-Projection-data |\n",
    "| **Fuente** | The Cancer Imaging Archive (TCIA) |\n",
    "| **Tamaño** | 1.32 TB (299 casos) |\n",
    "| **Formato** | DICOM estándar + DICOM-CT-PD (proyecciones) |\n",
    "| **Dosis** | Full-dose (100%) + Quarter-dose (25%) |\n",
    "| **Anatomía** | Cabeza, Tórax, Abdomen |\n",
    "| **DOI** | [10.7937/9npb-2637](https://doi.org/10.7937/9npb-2637) |\n",
    "\n",
    "### Cómo descargar:\n",
    "\n",
    "1. Visitar: https://www.cancerimagingarchive.net/collection/ldct-and-projection-data/\n",
    "2. Descargar el NBIA Data Retriever\n",
    "3. Seleccionar los casos deseados (Chest para pulmón)\n",
    "4. Descargar imágenes DICOM\n",
    "\n",
    "### Estructura esperada:\n",
    "```\n",
    "Mayo_LDCT/\n",
    "├── L001/                    # Paciente 001\n",
    "│   ├── full_dose/          # Imágenes NDCT (100% dosis)\n",
    "│   │   └── *.dcm\n",
    "│   └── quarter_dose/       # Imágenes LDCT (25% dosis)\n",
    "│       └── *.dcm\n",
    "├── L002/\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CARGA DE DATOS MAYO CLINIC LDCT (TCIA)\n# ============================================================\n# MAYO_PATH y MAYO_AVAILABLE ya estan definidos en celdas iniciales\n\nprint(\"=\"*60)\nprint(\"CARGADOR DE DATOS MAYO CLINIC\")\nprint(\"=\"*60)\n\nif MAYO_AVAILABLE:\n    print(f\"[OK] Dataset Mayo disponible en: {MAYO_PATH}\")\n    dcm_count = len(list(Path(MAYO_PATH).rglob(\"*.dcm\")))\n    print(f\"    Archivos DICOM: {dcm_count}\")\nelse:\n    print(\"[INFO] Dataset Mayo NO disponible\")\n    print(\"       El notebook usara ruido simulado con LUNA16\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "from glob import glob\n",
    "\n",
    "class MayoLDCTLoader:\n",
    "    \"\"\"\n",
    "    Cargador para el dataset Mayo Clinic LDCT (TCIA)\n",
    "    \n",
    "    El dataset contiene pares de imágenes:\n",
    "    - Full-dose (NDCT): 100% de la dosis de radiación\n",
    "    - Quarter-dose (LDCT): 25% de la dosis (simulado con ruido Poisson)\n",
    "    \n",
    "    Referencia: Chen et al. 2016 - SPIE Medical Imaging\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_path):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            base_path: Ruta base del dataset Mayo_LDCT\n",
    "        \"\"\"\n",
    "        self.base_path = Path(base_path)\n",
    "        self.patients = self._find_patients()\n",
    "        \n",
    "    def _find_patients(self):\n",
    "        \"\"\"Encuentra todos los pacientes disponibles\"\"\"\n",
    "        patients = []\n",
    "        \n",
    "        # Buscar carpetas de pacientes (formato L001, L002, etc.)\n",
    "        for patient_dir in sorted(self.base_path.glob(\"L*\")):\n",
    "            if patient_dir.is_dir():\n",
    "                patients.append(patient_dir.name)\n",
    "        \n",
    "        # También buscar formato alternativo (carpetas con SeriesInstanceUID)\n",
    "        if len(patients) == 0:\n",
    "            for patient_dir in sorted(self.base_path.iterdir()):\n",
    "                if patient_dir.is_dir():\n",
    "                    patients.append(patient_dir.name)\n",
    "        \n",
    "        return patients\n",
    "    \n",
    "    def _find_dose_folders(self, patient_id):\n",
    "        \"\"\"\n",
    "        Encuentra las carpetas de full-dose y quarter-dose para un paciente\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (full_dose_path, quarter_dose_path) o (None, None) si no encuentra\n",
    "        \"\"\"\n",
    "        patient_path = self.base_path / patient_id\n",
    "        \n",
    "        full_dose = None\n",
    "        quarter_dose = None\n",
    "        \n",
    "        # Buscar por nombre de carpeta\n",
    "        for folder in patient_path.rglob(\"*\"):\n",
    "            if folder.is_dir():\n",
    "                folder_lower = folder.name.lower()\n",
    "                \n",
    "                # Detectar full dose\n",
    "                if any(x in folder_lower for x in ['full', '100', 'nd', 'normal']):\n",
    "                    full_dose = folder\n",
    "                # Detectar quarter dose  \n",
    "                elif any(x in folder_lower for x in ['quarter', '25', 'ld', 'low']):\n",
    "                    quarter_dose = folder\n",
    "                # Detectar por contenido de DICOM\n",
    "                elif not full_dose or not quarter_dose:\n",
    "                    dcm_files = list(folder.glob(\"*.dcm\"))\n",
    "                    if dcm_files:\n",
    "                        try:\n",
    "                            ds = pydicom.dcmread(str(dcm_files[0]), stop_before_pixels=True)\n",
    "                            # Intentar detectar por metadatos\n",
    "                            if hasattr(ds, 'SeriesDescription'):\n",
    "                                desc = ds.SeriesDescription.lower()\n",
    "                                if 'full' in desc or '100' in desc:\n",
    "                                    full_dose = folder\n",
    "                                elif 'quarter' in desc or '25' in desc:\n",
    "                                    quarter_dose = folder\n",
    "                        except:\n",
    "                            pass\n",
    "        \n",
    "        return full_dose, quarter_dose\n",
    "    \n",
    "    def load_dicom_series(self, folder_path):\n",
    "        \"\"\"\n",
    "        Carga una serie DICOM completa y la convierte a volumen 3D\n",
    "        \n",
    "        Args:\n",
    "            folder_path: Ruta a la carpeta con archivos .dcm\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (volumen_3d, spacing, origin)\n",
    "        \"\"\"\n",
    "        folder_path = Path(folder_path)\n",
    "        dcm_files = sorted(folder_path.glob(\"*.dcm\"))\n",
    "        \n",
    "        if len(dcm_files) == 0:\n",
    "            # Buscar en subcarpetas\n",
    "            dcm_files = sorted(folder_path.rglob(\"*.dcm\"))\n",
    "        \n",
    "        if len(dcm_files) == 0:\n",
    "            raise ValueError(f\"No se encontraron archivos DICOM en {folder_path}\")\n",
    "        \n",
    "        # Leer todos los slices\n",
    "        slices = []\n",
    "        for dcm_file in dcm_files:\n",
    "            ds = pydicom.dcmread(str(dcm_file))\n",
    "            slices.append(ds)\n",
    "        \n",
    "        # Ordenar por posición Z\n",
    "        slices.sort(key=lambda x: float(x.ImagePositionPatient[2]))\n",
    "        \n",
    "        # Extraer información espacial\n",
    "        pixel_spacing = slices[0].PixelSpacing\n",
    "        slice_thickness = slices[0].SliceThickness if hasattr(slices[0], 'SliceThickness') else 1.0\n",
    "        spacing = np.array([slice_thickness, pixel_spacing[0], pixel_spacing[1]])\n",
    "        origin = np.array(slices[0].ImagePositionPatient)\n",
    "        \n",
    "        # Construir volumen 3D\n",
    "        volume = np.stack([s.pixel_array for s in slices])\n",
    "        \n",
    "        # Convertir a valores HU\n",
    "        intercept = slices[0].RescaleIntercept if hasattr(slices[0], 'RescaleIntercept') else 0\n",
    "        slope = slices[0].RescaleSlope if hasattr(slices[0], 'RescaleSlope') else 1\n",
    "        volume = volume * slope + intercept\n",
    "        \n",
    "        return volume.astype(np.float32), spacing, origin\n",
    "    \n",
    "    def load_patient_pair(self, patient_id):\n",
    "        \"\"\"\n",
    "        Carga el par NDCT/LDCT para un paciente\n",
    "        \n",
    "        Args:\n",
    "            patient_id: ID del paciente (ej: 'L001')\n",
    "            \n",
    "        Returns:\n",
    "            dict: {\n",
    "                'ndct': volumen full-dose,\n",
    "                'ldct': volumen quarter-dose,\n",
    "                'spacing': espaciado,\n",
    "                'patient_id': ID\n",
    "            }\n",
    "        \"\"\"\n",
    "        full_path, quarter_path = self._find_dose_folders(patient_id)\n",
    "        \n",
    "        if full_path is None or quarter_path is None:\n",
    "            raise ValueError(f\"No se encontraron carpetas full/quarter dose para {patient_id}\")\n",
    "        \n",
    "        print(f\"Cargando {patient_id}...\")\n",
    "        print(f\"  Full dose: {full_path}\")\n",
    "        print(f\"  Quarter dose: {quarter_path}\")\n",
    "        \n",
    "        ndct, spacing, origin = self.load_dicom_series(full_path)\n",
    "        ldct, _, _ = self.load_dicom_series(quarter_path)\n",
    "        \n",
    "        return {\n",
    "            'ndct': ndct,\n",
    "            'ldct': ldct,\n",
    "            'spacing': spacing,\n",
    "            'origin': origin,\n",
    "            'patient_id': patient_id\n",
    "        }\n",
    "    \n",
    "    def get_slice_pair(self, patient_id, slice_idx):\n",
    "        \"\"\"\n",
    "        Obtiene un par de slices NDCT/LDCT\n",
    "        \n",
    "        Args:\n",
    "            patient_id: ID del paciente\n",
    "            slice_idx: Índice del slice\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (ndct_slice, ldct_slice)\n",
    "        \"\"\"\n",
    "        data = self.load_patient_pair(patient_id)\n",
    "        return data['ndct'][slice_idx], data['ldct'][slice_idx]\n",
    "\n",
    "\n",
    "# Crear loader si el dataset está disponible\n",
    "if MAYO_AVAILABLE:\n",
    "    mayo_loader = MayoLDCTLoader(MAYO_PATH)\n",
    "    print(f\"\\nPacientes encontrados: {len(mayo_loader.patients)}\")\n",
    "    if len(mayo_loader.patients) > 0:\n",
    "        print(f\"Primeros pacientes: {mayo_loader.patients[:5]}\")\n",
    "else:\n",
    "    mayo_loader = None\n",
    "    print(\"\\nUsando datos simulados (LUNA16 + ruido sintético)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MayoLDCTDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset PyTorch para pares NDCT/LDCT del Mayo Clinic\n",
    "    \n",
    "    Extrae patches de pares reales full-dose/quarter-dose\n",
    "    para entrenamiento de modelos de denoising.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, mayo_loader, patient_ids=None, patch_size=64, \n",
    "                 num_patches_per_volume=200, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mayo_loader: Instancia de MayoLDCTLoader\n",
    "            patient_ids: Lista de IDs de pacientes a usar (None = todos)\n",
    "            patch_size: Tamaño del patch cuadrado\n",
    "            num_patches_per_volume: Patches a extraer por volumen\n",
    "            transform: Transformaciones opcionales\n",
    "        \"\"\"\n",
    "        self.loader = mayo_loader\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches_per_volume\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Usar todos los pacientes si no se especifica\n",
    "        if patient_ids is None:\n",
    "            self.patient_ids = mayo_loader.patients\n",
    "        else:\n",
    "            self.patient_ids = patient_ids\n",
    "        \n",
    "        # Cache de datos\n",
    "        self._cache = {}\n",
    "        self._load_data()\n",
    "    \n",
    "    def _load_data(self):\n",
    "        \"\"\"Carga los datos de todos los pacientes\"\"\"\n",
    "        print(f\"Cargando {len(self.patient_ids)} pacientes...\")\n",
    "        \n",
    "        for patient_id in tqdm(self.patient_ids):\n",
    "            try:\n",
    "                data = self.loader.load_patient_pair(patient_id)\n",
    "                self._cache[patient_id] = data\n",
    "            except Exception as e:\n",
    "                print(f\"Error cargando {patient_id}: {e}\")\n",
    "        \n",
    "        print(f\"Pacientes cargados: {len(self._cache)}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._cache) * self.num_patches\n",
    "    \n",
    "    def _normalize(self, image, min_hu=-1000, max_hu=400):\n",
    "        \"\"\"Normaliza valores HU a [0, 1]\"\"\"\n",
    "        image = np.clip(image, min_hu, max_hu)\n",
    "        return (image - min_hu) / (max_hu - min_hu)\n",
    "    \n",
    "    def _extract_random_patch(self, ndct_vol, ldct_vol):\n",
    "        \"\"\"Extrae un patch aleatorio del mismo lugar en ambos volúmenes\"\"\"\n",
    "        z, h, w = ndct_vol.shape\n",
    "        \n",
    "        # Seleccionar slice aleatorio (evitar bordes)\n",
    "        z_idx = np.random.randint(z // 4, 3 * z // 4)\n",
    "        \n",
    "        # Seleccionar posición aleatoria\n",
    "        y = np.random.randint(0, h - self.patch_size)\n",
    "        x = np.random.randint(0, w - self.patch_size)\n",
    "        \n",
    "        # Extraer patches\n",
    "        ndct_patch = ndct_vol[z_idx, y:y+self.patch_size, x:x+self.patch_size]\n",
    "        ldct_patch = ldct_vol[z_idx, y:y+self.patch_size, x:x+self.patch_size]\n",
    "        \n",
    "        return ndct_patch, ldct_patch\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Seleccionar paciente\n",
    "        patient_idx = idx // self.num_patches\n",
    "        patient_id = list(self._cache.keys())[patient_idx]\n",
    "        data = self._cache[patient_id]\n",
    "        \n",
    "        # Extraer patch\n",
    "        ndct_patch, ldct_patch = self._extract_random_patch(\n",
    "            data['ndct'], data['ldct']\n",
    "        )\n",
    "        \n",
    "        # Normalizar\n",
    "        ndct_patch = self._normalize(ndct_patch)\n",
    "        ldct_patch = self._normalize(ldct_patch)\n",
    "        \n",
    "        # Convertir a tensores\n",
    "        ndct_tensor = torch.FloatTensor(ndct_patch).unsqueeze(0)\n",
    "        ldct_tensor = torch.FloatTensor(ldct_patch).unsqueeze(0)\n",
    "        \n",
    "        # Aplicar transformaciones\n",
    "        if self.transform:\n",
    "            ndct_tensor = self.transform(ndct_tensor)\n",
    "            ldct_tensor = self.transform(ldct_tensor)\n",
    "        \n",
    "        # Retornar (ruidosa, limpia) para mantener consistencia con el dataset simulado\n",
    "        return ldct_tensor, ndct_tensor\n",
    "\n",
    "\n",
    "# Crear dataset si Mayo está disponible\n",
    "if MAYO_AVAILABLE and mayo_loader is not None and len(mayo_loader.patients) > 0:\n",
    "    print(\"Creando dataset con datos reales Mayo Clinic...\")\n",
    "    \n",
    "    # Usar primeros 5 pacientes para demo\n",
    "    demo_patients = mayo_loader.patients[:5]\n",
    "    mayo_dataset = MayoLDCTDataset(\n",
    "        mayo_loader, \n",
    "        patient_ids=demo_patients,\n",
    "        patch_size=64,\n",
    "        num_patches_per_volume=100\n",
    "    )\n",
    "    \n",
    "    mayo_dataloader = DataLoader(\n",
    "        mayo_dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nDataset Mayo creado:\")\n",
    "    print(f\"  Pacientes: {len(demo_patients)}\")\n",
    "    print(f\"  Total patches: {len(mayo_dataset)}\")\n",
    "else:\n",
    "    mayo_dataset = None\n",
    "    mayo_dataloader = None\n",
    "    print(\"\\nDataset Mayo no disponible, usar datos simulados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar ejemplos de datos reales (si están disponibles)\n",
    "if mayo_dataloader is not None:\n",
    "    print(\"Visualizando pares reales NDCT/LDCT del Mayo Clinic:\")\n",
    "    \n",
    "    ldct_batch, ndct_batch = next(iter(mayo_dataloader))\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    \n",
    "    for i in range(4):\n",
    "        # LDCT (ruidosa)\n",
    "        axes[0, i].imshow(ldct_batch[i, 0].numpy(), cmap='bone')\n",
    "        axes[0, i].set_title('LDCT Real (25% dosis)', fontsize=11)\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # NDCT (limpia)\n",
    "        axes[1, i].imshow(ndct_batch[i, 0].numpy(), cmap='bone')\n",
    "        axes[1, i].set_title('NDCT Real (100% dosis)', fontsize=11)\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Pares Reales NDCT/LDCT - Mayo Clinic Dataset', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calcular diferencia de ruido real\n",
    "    diff = np.abs(ldct_batch[0, 0].numpy() - ndct_batch[0, 0].numpy())\n",
    "    psnr_real = psnr(ndct_batch[0, 0].numpy(), ldct_batch[0, 0].numpy(), data_range=1.0)\n",
    "    \n",
    "    print(f\"\\nMétricas de ruido real (ejemplo):\")\n",
    "    print(f\"  PSNR LDCT vs NDCT: {psnr_real:.2f} dB\")\n",
    "    print(f\"  Diferencia media: {diff.mean():.4f}\")\n",
    "    print(f\"  Diferencia máx: {diff.max():.4f}\")\n",
    "else:\n",
    "    print(\"Dataset Mayo no disponible - usando datos simulados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Entrenamiento con Datos Reales Mayo Clinic\n",
    "\n",
    "Si el dataset Mayo está disponible, podemos entrenar el modelo DnCNN con pares reales NDCT/LDCT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar con datos reales Mayo (si están disponibles)\n",
    "if mayo_dataloader is not None:\n",
    "    print(\"=\"*60)\n",
    "    print(\"ENTRENAMIENTO CON DATOS REALES MAYO CLINIC\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Crear nuevo modelo para datos reales\n",
    "    model_mayo = DnCNN(in_channels=1, out_channels=1, num_features=64, depth=17).to(device)\n",
    "    \n",
    "    print(f\"\\nModelo DnCNN para Mayo Clinic:\")\n",
    "    print(f\"  Parámetros: {sum(p.numel() for p in model_mayo.parameters()):,}\")\n",
    "    \n",
    "    # Entrenar\n",
    "    print(\"\\nIniciando entrenamiento con datos reales...\")\n",
    "    history_mayo = train_denoiser(model_mayo, mayo_dataloader, epochs=10, lr=1e-3)\n",
    "    \n",
    "    # Guardar modelo\n",
    "    mayo_model_path = os.path.join(weights_dir, 'dncnn_mayo_real.pth')\n",
    "    torch.save(model_mayo.state_dict(), mayo_model_path)\n",
    "    print(f\"\\nModelo Mayo guardado en: {mayo_model_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Dataset Mayo no disponible\")\n",
    "    print(\"El modelo fue entrenado con ruido simulado (ver secciones anteriores)\")\n",
    "    print(\"\\nPara entrenar con datos reales:\")\n",
    "    print(\"1. Descargar de: https://www.cancerimagingarchive.net/collection/ldct-and-projection-data/\")\n",
    "    print(\"2. Colocar en carpeta 'Mayo_LDCT'\")\n",
    "    print(\"3. Re-ejecutar este notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12. Resumen y Referencias\n",
    "\n",
    "### Logros de este notebook:\n",
    "\n",
    "1. **Simulación de ruido LDCT** a partir de imágenes NDCT (Gaussiano, Poisson, CT realista)\n",
    "2. **Comparación de técnicas clásicas** de denoising (Bilateral, TV, NLM)\n",
    "3. **Implementación de DnCNN** para denoising con deep learning\n",
    "4. **Soporte para dataset Mayo Clinic** con pares NDCT/LDCT reales\n",
    "\n",
    "### Modelos guardados:\n",
    "\n",
    "| Modelo | Datos | Archivo |\n",
    "|--------|-------|---------|\n",
    "| DnCNN (simulado) | LUNA16 + ruido sintético | `weights/dncnn_denoising.pth` |\n",
    "| DnCNN (real) | Mayo Clinic LDCT | `weights/dncnn_mayo_real.pth` |\n",
    "\n",
    "### Referencias:\n",
    "\n",
    "1. **Paper del dataset Mayo Clinic**:\n",
    "   - Chen B. et al. (2016). \"An Open Library of CT Patient Projection Data\". SPIE Medical Imaging.\n",
    "   - DOI: [10.1117/12.2216823](https://doi.org/10.1117/12.2216823)\n",
    "\n",
    "2. **Dataset TCIA**:\n",
    "   - LDCT-and-Projection-data\n",
    "   - DOI: [10.7937/9npb-2637](https://doi.org/10.7937/9npb-2637)\n",
    "   - URL: https://www.cancerimagingarchive.net/collection/ldct-and-projection-data/\n",
    "\n",
    "3. **DnCNN**:\n",
    "   - Zhang K. et al. (2017). \"Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising\". IEEE TIP.\n",
    "\n",
    "4. **AAPM Low Dose CT Grand Challenge**:\n",
    "   - https://www.aapm.org/grandchallenge/lowdosect/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\"*60)\nprint(\"RESUMEN DEL NOTEBOOK 05: DENOISING\")\nprint(\"=\"*60)\n\nprint(\"\\n1. MODELOS DE RUIDO:\")\nprint(\"   - Gaussiano (aditivo)\")\nprint(\"   - Poisson (cuantico)\")\nprint(\"   - LDCT realista (combinado)\")\n\nprint(\"\\n2. TECNICAS DE DENOISING:\")\nprint(\"   Clasicas: Gaussiano, Mediana, Bilateral, TV, NLM\")\nprint(\"   Deep Learning: DnCNN (17 capas, residual learning)\")\n\nprint(\"\\n3. DATASETS SOPORTADOS:\")\nif MAYO_AVAILABLE:\n    mayo_patients = len(mayo_loader.patients) if mayo_loader else 0\n    print(f\"   - Mayo Clinic: Pares reales NDCT/LDCT ({mayo_patients} pacientes)\")\nelse:\n    print(\"   - LUNA16: Ruido simulado\")\n    print(\"   - Mayo Clinic: No descargado (ver instrucciones arriba)\")\n\nprint(\"\\n4. RESULTADOS:\")\nif results is not None:\n    print(f\"   LDCT sin procesar: {results['psnr_noisy']:.2f} dB\")\n    print(f\"   DnCNN:             {results['psnr_denoised']:.2f} dB (+{results['psnr_gain']:.2f} dB)\")\nelif MAYO_AVAILABLE:\n    print(\"   Ver seccion de entrenamiento con datos Mayo\")\nelse:\n    print(\"   Ejecutar celdas de entrenamiento primero\")\n\nprint(\"\\n5. ARCHIVOS GENERADOS:\")\nprint(f\"   - {weights_dir}/dncnn_denoising.pth (ruido simulado)\")\nif MAYO_AVAILABLE:\n    print(f\"   - {weights_dir}/dncnn_mayo_real.pth (datos reales)\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Para mejorar resultados:\")\nprint(\"  1. Descargar Mayo Clinic LDCT de TCIA (si no disponible)\")\nprint(\"  2. Entrenar mas epocas (50-100)\")\nprint(\"  3. Usar arquitecturas avanzadas (RED-CNN, WGAN)\")\nprint(\"=\"*60)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}